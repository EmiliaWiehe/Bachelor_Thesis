{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.data_loader import get_dataloaders\n",
    "from src.log import log_experiment_results, save_loss_curve, save_confusion_matrix\n",
    "from src.res_model import build_resnet_model\n",
    "from src.early_stopping import EarlyStopping\n",
    "\n",
    "# Secure W&B Login\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameter options\n",
    "pretrained_options = [True, False]\n",
    "learning_rates = [0.001, 0.0001, 0.00001]\n",
    "batch_sizes = [ 8, 16, 32]\n",
    "epochs = 30\n",
    "augmentation = False\n",
    "use_stable_diffusion = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data set - remember to change the directroy path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_stable_diffusion:\n",
    "    data_dir = r\"C:\\Users\\OMEN\\Documents\\BA_Code\\stable_diffusion_data\"\n",
    "else:\n",
    "    data_dir = r\"C:\\Users\\OMEN\\Documents\\BA_Code\\data\"\n",
    "# Load dataset (train & validation loaders)\n",
    "train_loader, val_loader = get_dataloaders(data_dir, augment=augmentation)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names\n",
    "class_names = [\"lie\", \"run\", \"sit\", \"walk_stand\"]\n",
    "# Define class mapping (make sure it matches your labels)\n",
    "class_map = {\"lie\": 0, \"run\": 1, \"sit\": 2, \"walk_stand\": 3}\n",
    "\n",
    "predictions_data = []  # Collect predictions and true labels\n",
    "\n",
    "# Initialize Early Stopping\n",
    "early_stopping = EarlyStopping(patience=4)\n",
    "best_val_loss = float(\"inf\")\n",
    "best_conf_matrix_path = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop, saved on weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pretrained in tqdm(pretrained_options, desc=\"Pretrained Options\"):\n",
    "    for lr in tqdm(learning_rates, desc=\"Learning Rates\"):\n",
    "        for batch_size in tqdm(batch_sizes, desc=\"Batch Sizes\"):\n",
    "            # Initialize W&B run\n",
    "            wandb.init(\n",
    "                project=\"animal-posture-classification\",\n",
    "                config={\n",
    "                    \"model\": \"ResNet50\",\n",
    "                    \"pretrained\": pretrained,\n",
    "                    \"learning_rate\": lr,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"epochs\": epochs,\n",
    "                    \"data_augmentation\": augmentation,\n",
    "                    \"stable_diffusion\": use_stable_diffusion,\n",
    "                }\n",
    "            )\n",
    "            train_loader, val_loader = get_dataloaders(data_dir,batch_size= batch_size, augment=False)\n",
    "\n",
    "            # Initialize model\n",
    "            model = build_resnet_model(pretrained=pretrained, num_classes=len(class_names)).to(device)\n",
    "            \n",
    "            # Define Loss Function & Optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr) \n",
    "\n",
    "            # Early Stopping Reset for Each Run\n",
    "            early_stopping = EarlyStopping(patience=4)\n",
    "\n",
    "            try:\n",
    "                for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "                    start_time = time.time()\n",
    "                    model.train()\n",
    "                    train_loss = 0.0\n",
    "\n",
    "                    for images, labels in train_loader:\n",
    "                        images, labels = images.to(device), labels.to(device)\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(images)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        loss.backward()\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) \n",
    "                        optimizer.step()\n",
    "\n",
    "                        train_loss += loss.item()\n",
    "\n",
    "                    train_loss /= len(train_loader)\n",
    "\n",
    "                    # Validation\n",
    "                    model.eval()\n",
    "                    val_loss = 0.0\n",
    "                    all_preds, all_labels = [], []\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        for images, labels in val_loader:\n",
    "                            images, labels = images.to(device), labels.to(device)\n",
    "                            outputs = model(images)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            val_loss += loss.item()\n",
    "\n",
    "                            preds = torch.argmax(outputs, dim=1)\n",
    "                            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "                            all_labels.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "                    val_loss /= len(val_loader)\n",
    "                    accuracy = accuracy_score(all_labels, all_preds)\n",
    "                    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True, zero_division=0)\n",
    "\n",
    "                    # Create target directory if it doesn't exist\n",
    "                    conf_matrix_dir = Path(\"results/confusion_matrices\")\n",
    "                    conf_matrix_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                    # Save and Log Confusion Matrix\n",
    "                    cm = confusion_matrix(all_labels, all_preds)\n",
    "                    plt.figure(figsize=(6, 6))\n",
    "                    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "                    plt.xlabel(\"Predicted\")\n",
    "                    plt.ylabel(\"True\")\n",
    "\n",
    "                    # Save to results/confusion_matrices/\n",
    "                    cm_path = conf_matrix_dir / f\"conf_matrix_epoch{epoch+1}.png\"\n",
    "                    plt.savefig(cm_path)\n",
    "                    plt.close()\n",
    "\n",
    "                    # Always log confusion matrix\n",
    "                    wandb.log({\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"train_loss\": train_loss,\n",
    "                        \"val_loss\": val_loss,\n",
    "                        \"val_accuracy\": accuracy,\n",
    "                        \"conf_matrix\": wandb.Image(cm_path),\n",
    "                        \"precision\": report[\"weighted avg\"][\"precision\"],\n",
    "                        \"recall\": report[\"weighted avg\"][\"recall\"],\n",
    "                        \"f1_score\": report[\"weighted avg\"][\"f1-score\"],\n",
    "                        \"actual_epochs\": epoch + 1  \n",
    "                    })\n",
    "\n",
    "                    # **Save the Best Confusion Matrix**\n",
    "                    if val_loss < best_val_loss:\n",
    "                        best_val_loss = val_loss\n",
    "                        best_conf_matrix_path = cm_path  \n",
    "\n",
    "                    # **Check Early Stopping Condition**\n",
    "                    if early_stopping(val_loss, model):  \n",
    "                        print(f\"Early stopping triggered at epoch {epoch + 1}. Stopping training.\")\n",
    "                        break\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in training: {e}\")\n",
    "            finally:\n",
    "                # **Log Best Confusion Matrix Separately (Final Run)**\n",
    "                if best_conf_matrix_path:\n",
    "                    wandb.log({\"Confusion Matrix\": wandb.Image(best_conf_matrix_path)})\n",
    "                \n",
    "                # Save the model\n",
    "                wandb.finish()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
