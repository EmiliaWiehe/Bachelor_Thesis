{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# change the path to your data results file\n",
    "df = pd.read_csv(\"results_data.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "configs = [\n",
    "    (\"False\", \"false\"),\n",
    "    (\"False\", \"True\"),\n",
    "    (\"True\", \"False\"),\n",
    "    (\"True\", \"True\")\n",
    "]\n",
    "\n",
    "metric = \"val_accuracy\"\n",
    "\n",
    "# vit vs resnet\n",
    "vit_vs_resnet_split = []\n",
    "\n",
    "for pretrained_setting in [True, False]:\n",
    "    for sd, aug in configs:\n",
    "        subset = df[\n",
    "            (df['pretrained'] == pretrained_setting) &\n",
    "            (df['stable_diffusion'] == sd) &\n",
    "            (df['data_augmentation'] == aug) &\n",
    "            (df['model'].isin(['ViT', 'ResNet50']))\n",
    "        ]\n",
    "\n",
    "        vit_vals = subset[subset['model'] == 'ViT'][metric].reset_index(drop=True)\n",
    "        resnet_vals = subset[subset['model'] == 'ResNet50'][metric].reset_index(drop=True)\n",
    "\n",
    "        min_len = min(len(vit_vals), len(resnet_vals))\n",
    "        vit_vals = vit_vals[:min_len]\n",
    "        resnet_vals = resnet_vals[:min_len]\n",
    "\n",
    "        if min_len > 2:\n",
    "            t_stat, t_pval = ttest_rel(vit_vals, resnet_vals)\n",
    "        else:\n",
    "            t_stat = t_pval = None\n",
    "\n",
    "        vit_vs_resnet_split.append({\n",
    "            \"comparison\": \"ViT vs ResNet50\",\n",
    "            \"pretrained\": pretrained_setting,\n",
    "            \"model\": \"ViT vs ResNet50\",\n",
    "            \"stable_diffusion\": sd,\n",
    "            \"data_augmentation\": aug,\n",
    "            \"n_pairs\": min_len,\n",
    "            \"t_statistic\": t_stat,\n",
    "            \"t_p_value\": t_pval\n",
    "        })\n",
    "\n",
    "\n",
    "# Pretrained vs Non-Pretrained\n",
    "pretrained_comparisons = []\n",
    "\n",
    "for model_type in ['ViT', 'ResNet50']:\n",
    "    for sd, aug in configs:\n",
    "        subset = df[\n",
    "            (df['model'] == model_type) &\n",
    "            (df['stable_diffusion'] == sd) &\n",
    "            (df['data_augmentation'] == aug)\n",
    "        ]\n",
    "\n",
    "        pre_vals = subset[subset['pretrained'] == True][metric].reset_index(drop=True)\n",
    "        nonpre_vals = subset[subset['pretrained'] == False][metric].reset_index(drop=True)\n",
    "\n",
    "        min_len = min(len(pre_vals), len(nonpre_vals))\n",
    "        pre_vals = pre_vals[:min_len]\n",
    "        nonpre_vals = nonpre_vals[:min_len]\n",
    "\n",
    "        if min_len > 2:\n",
    "            t_stat, t_pval = ttest_rel(pre_vals, nonpre_vals)\n",
    "        else:\n",
    "            t_stat = t_pval = None\n",
    "\n",
    "        pretrained_comparisons.append({\n",
    "            \"comparison\": \"Pretrained vs Non-Pretrained\",\n",
    "            \"pretrained\": \"True vs False\",\n",
    "            \"model\": model_type,\n",
    "            \"stable_diffusion\": sd,\n",
    "            \"data_augmentation\": aug,\n",
    "            \"n_pairs\": min_len,\n",
    "            \"t_statistic\": t_stat,\n",
    "            \"t_p_value\": t_pval\n",
    "        })\n",
    "\n",
    "# --- Combine all results ---\n",
    "all_results = pd.DataFrame(vit_vs_resnet_split + pretrained_comparisons)\n",
    "print(all_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate mean acc, pre and f1 score and their standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.groupby([\"model\", \"pretrained\", \"stable_diffusion\", \"data_augmentation\"])\n",
    "\n",
    "# print model = vit, pretrained = true, stable_diffusion = true, data_augmentation = flip\n",
    "for pretrained in [True]:\n",
    "    for stable_diffusion in [\"True\", \"False\"]:\n",
    "        for data_augmentation in [\"True\", \"False\"]:\n",
    "            print(f\"Model: ViT, Pretrained: {pretrained}, Stable Diffusion: {stable_diffusion}, Data Augmentation: {data_augmentation}\")\n",
    "            temp = new_df[(new_df[\"model\"] == \"ViT\") & (new_df[\"pretrained\"] == pretrained) & (new_df[\"stable_diffusion\"] == stable_diffusion) & (new_df[\"data_augmentation\"] == data_augmentation)]\n",
    "            # calculate the mean and std of val_accuracy\n",
    "            mean_val_accuracy = temp[\"val_accuracy\"].mean()\n",
    "            mean_precision = temp[\"precision\"].mean()\n",
    "            mean_f1_score = temp[\"f1_score\"].mean()\n",
    "            std_val_accuracy = temp[\"val_accuracy\"].std()\n",
    "            std_precision = temp[\"precision\"].std()\n",
    "            std_f1_score = temp[\"f1_score\"].std()\n",
    "            # print the mean and std\n",
    "            print(f\"Mean Val Accuracy: {mean_val_accuracy}, Std Val Accuracy: {std_val_accuracy}\")\n",
    "            print(f\"Mean Precision: {mean_precision}, Std Precision: {std_precision}\")\n",
    "            print(f\"Mean F1 Score: {mean_f1_score}, Std F1 Score: {std_f1_score}\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
